{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"output_files/combined.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ART_CODE</th>\n",
       "      <th>DESC_CODED</th>\n",
       "      <th>HLGT_NAME_COMPL</th>\n",
       "      <th>HLT_NAME_COMPL</th>\n",
       "      <th>INC_CODE</th>\n",
       "      <th>INC_CODE_J</th>\n",
       "      <th>LLT_NAME_COMPL</th>\n",
       "      <th>PT_NAME_COMPL</th>\n",
       "      <th>REPORTED_TERM</th>\n",
       "      <th>SOC_CODE</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hyponatraemia</td>\n",
       "      <td>ELECTROLYTE AND FLUID BALANCE CONDITIONS</td>\n",
       "      <td>SODIUM IMBALANCE</td>\n",
       "      <td>10021038.0</td>\n",
       "      <td>10021036</td>\n",
       "      <td>HYPONATREMIA</td>\n",
       "      <td>HYPONATRAEMIA</td>\n",
       "      <td>HYPONATREMIA</td>\n",
       "      <td>10027433.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subacute cutaneous lupus erythematosus</td>\n",
       "      <td>EPIDERMAL AND DERMAL CONDITIONS</td>\n",
       "      <td>CONNECTIVE TISSUE DISORDERS</td>\n",
       "      <td>10057903.0</td>\n",
       "      <td>10057903</td>\n",
       "      <td>SUBACUTE CUTANEOUS LUPUS ERYTHEMATOSUS</td>\n",
       "      <td>SUBACUTE CUTANEOUS LUPUS ERYTHEMATOSUS</td>\n",
       "      <td>OMEPRAZOLE INDUCED SUBACUTE CUTANEOUS LUPUS ER...</td>\n",
       "      <td>10040785.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Blood bilirubin unconjugated increased</td>\n",
       "      <td>HEPATOBILIARY INVESTIGATIONS</td>\n",
       "      <td>LIVER FUNCTION ANALYSES</td>\n",
       "      <td>10021709.0</td>\n",
       "      <td>10021709</td>\n",
       "      <td>INDIRECT BILIRUBIN INCREASED</td>\n",
       "      <td>BLOOD BILIRUBIN UNCONJUGATED INCREASED</td>\n",
       "      <td>INDIRECT BILIRUBIN (74.7 MICROMOL/L)</td>\n",
       "      <td>10022891.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>toxic epidermal necrolysis</td>\n",
       "      <td>EPIDERMAL AND DERMAL CONDITIONS</td>\n",
       "      <td>BULLOUS CONDITIONS</td>\n",
       "      <td>10044223.0</td>\n",
       "      <td>10044223</td>\n",
       "      <td>TOXIC EPIDERMAL NECROLYSIS</td>\n",
       "      <td>TOXIC EPIDERMAL NECROLYSIS</td>\n",
       "      <td>TOXIC EPIDERMAL NECROLYSIS</td>\n",
       "      <td>10040785.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bradycardia</td>\n",
       "      <td>CARDIAC ARRHYTHMIAS</td>\n",
       "      <td>RATE AND RHYTHM DISORDERS NEC</td>\n",
       "      <td>10006093.0</td>\n",
       "      <td>10006093</td>\n",
       "      <td>BRADYCARDIA</td>\n",
       "      <td>BRADYCARDIA</td>\n",
       "      <td>BRADYCARDIA</td>\n",
       "      <td>10007541.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ART_CODE                              DESC_CODED  \\\n",
       "0         0                           Hyponatraemia   \n",
       "1         1  Subacute cutaneous lupus erythematosus   \n",
       "2         2  Blood bilirubin unconjugated increased   \n",
       "3         3              toxic epidermal necrolysis   \n",
       "4         4                             Bradycardia   \n",
       "\n",
       "                            HLGT_NAME_COMPL                 HLT_NAME_COMPL  \\\n",
       "0  ELECTROLYTE AND FLUID BALANCE CONDITIONS               SODIUM IMBALANCE   \n",
       "1           EPIDERMAL AND DERMAL CONDITIONS    CONNECTIVE TISSUE DISORDERS   \n",
       "2              HEPATOBILIARY INVESTIGATIONS        LIVER FUNCTION ANALYSES   \n",
       "3           EPIDERMAL AND DERMAL CONDITIONS             BULLOUS CONDITIONS   \n",
       "4                       CARDIAC ARRHYTHMIAS  RATE AND RHYTHM DISORDERS NEC   \n",
       "\n",
       "     INC_CODE  INC_CODE_J                          LLT_NAME_COMPL  \\\n",
       "0  10021038.0    10021036                            HYPONATREMIA   \n",
       "1  10057903.0    10057903  SUBACUTE CUTANEOUS LUPUS ERYTHEMATOSUS   \n",
       "2  10021709.0    10021709            INDIRECT BILIRUBIN INCREASED   \n",
       "3  10044223.0    10044223              TOXIC EPIDERMAL NECROLYSIS   \n",
       "4  10006093.0    10006093                             BRADYCARDIA   \n",
       "\n",
       "                            PT_NAME_COMPL  \\\n",
       "0                           HYPONATRAEMIA   \n",
       "1  SUBACUTE CUTANEOUS LUPUS ERYTHEMATOSUS   \n",
       "2  BLOOD BILIRUBIN UNCONJUGATED INCREASED   \n",
       "3              TOXIC EPIDERMAL NECROLYSIS   \n",
       "4                             BRADYCARDIA   \n",
       "\n",
       "                                       REPORTED_TERM    SOC_CODE  len  \n",
       "0                                       HYPONATREMIA  10027433.0    1  \n",
       "1  OMEPRAZOLE INDUCED SUBACUTE CUTANEOUS LUPUS ER...  10040785.0    4  \n",
       "2               INDIRECT BILIRUBIN (74.7 MICROMOL/L)  10022891.0    4  \n",
       "3                         TOXIC EPIDERMAL NECROLYSIS  10040785.0    3  \n",
       "4                                        BRADYCARDIA  10007541.0    1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 26000\n",
    "MAX_LEN = 40\n",
    "EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df_train.REPORTED_TERM)\n",
    "sequences = tokenizer.texts_to_sequences(df_train.REPORTED_TERM)\n",
    "x = pad_sequences(sequences, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16834"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = pathlib.Path(\"glove/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(GLOVE_DIR/'glove.6B.200d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16835, 200)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train.ART_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout, SpatialDropout1D, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, EMBEDDING_DIM, input_length=x.shape[1], weights=[embedding_matrix]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50586 samples, validate on 12647 samples\n",
      "Epoch 1/30\n",
      "50586/50586 [==============================] - 93s 2ms/step - loss: 6.8916 - categorical_accuracy: 0.0331 - val_loss: 6.3450 - val_categorical_accuracy: 0.0339\n",
      "Epoch 2/30\n",
      "50586/50586 [==============================] - 86s 2ms/step - loss: 5.8066 - categorical_accuracy: 0.1087 - val_loss: 5.2981 - val_categorical_accuracy: 0.1820\n",
      "Epoch 3/30\n",
      "50586/50586 [==============================] - 87s 2ms/step - loss: 4.7825 - categorical_accuracy: 0.2538 - val_loss: 4.4563 - val_categorical_accuracy: 0.3375\n",
      "Epoch 4/30\n",
      "50586/50586 [==============================] - 87s 2ms/step - loss: 3.9842 - categorical_accuracy: 0.3828 - val_loss: 3.8639 - val_categorical_accuracy: 0.4356\n",
      "Epoch 5/30\n",
      "50586/50586 [==============================] - 89s 2ms/step - loss: 3.3876 - categorical_accuracy: 0.4697 - val_loss: 3.4369 - val_categorical_accuracy: 0.5094\n",
      "Epoch 6/30\n",
      "50586/50586 [==============================] - 86s 2ms/step - loss: 2.9292 - categorical_accuracy: 0.5353 - val_loss: 3.1219 - val_categorical_accuracy: 0.5554\n",
      "Epoch 7/30\n",
      "50586/50586 [==============================] - 88s 2ms/step - loss: 2.5707 - categorical_accuracy: 0.5863 - val_loss: 2.8959 - val_categorical_accuracy: 0.5892\n",
      "Epoch 8/30\n",
      "50586/50586 [==============================] - 88s 2ms/step - loss: 2.2865 - categorical_accuracy: 0.6235 - val_loss: 2.7237 - val_categorical_accuracy: 0.6103\n",
      "Epoch 9/30\n",
      "50586/50586 [==============================] - 83s 2ms/step - loss: 2.0567 - categorical_accuracy: 0.6539 - val_loss: 2.5941 - val_categorical_accuracy: 0.6296\n",
      "Epoch 10/30\n",
      "50586/50586 [==============================] - 87s 2ms/step - loss: 1.8581 - categorical_accuracy: 0.6808 - val_loss: 2.4932 - val_categorical_accuracy: 0.6421\n",
      "Epoch 11/30\n",
      "50586/50586 [==============================] - 84s 2ms/step - loss: 1.6947 - categorical_accuracy: 0.7007 - val_loss: 2.4098 - val_categorical_accuracy: 0.6570\n",
      "Epoch 12/30\n",
      "50586/50586 [==============================] - 88s 2ms/step - loss: 1.5503 - categorical_accuracy: 0.7214 - val_loss: 2.3414 - val_categorical_accuracy: 0.6672\n",
      "Epoch 13/30\n",
      "50586/50586 [==============================] - 85s 2ms/step - loss: 1.4245 - categorical_accuracy: 0.7391 - val_loss: 2.2895 - val_categorical_accuracy: 0.6736\n",
      "Epoch 14/30\n",
      "50586/50586 [==============================] - 87s 2ms/step - loss: 1.3148 - categorical_accuracy: 0.7547 - val_loss: 2.2502 - val_categorical_accuracy: 0.6793\n",
      "Epoch 15/30\n",
      "30464/50586 [=================>............] - ETA: 33s - loss: 1.2272 - categorical_accuracy: 0.7686"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=epochs, batch_size=batch_size,\n",
    "    validation_data=[x_test, y_test],\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(),\n",
    "        EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001),\n",
    "        ModelCheckpoint(filepath='model-LSTM-word2vec.h5', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
