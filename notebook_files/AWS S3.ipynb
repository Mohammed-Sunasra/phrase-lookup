{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use Amazon S3\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = s3.Bucket('phrase-lookup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading File:  \n",
      "Downloading File:  \n",
      "Downloading File:  \n",
      "Downloading File:  \n",
      "Downloading File:  meddra.csv\n",
      "Downloading File:  \n",
      "Downloading File:  test.csv\n",
      "Downloading File:  \n",
      "Downloading File:  train.csv\n",
      "Downloading File:  \n",
      "Downloading File:  \n",
      "Downloading File:  glove.6B.200d.txt\n",
      "Downloading File:  model_lstm_best_weights_v1.h5\n",
      "Downloading File:  model_lstm_v1.json\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "count = 1\n",
    "dir_list = ['']\n",
    "for obj in my_bucket.objects.all():\n",
    "    path, filename = os.path.split(obj.key)\n",
    "    print(\"Downloading File: \", filename)\n",
    "    if path not in dir_list:\n",
    "        dir_list.append(path)\n",
    "    \n",
    "    path = Path(path)\n",
    "    filename_path = Path(path / filename)\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "    if filename not in dir_list:\n",
    "        s3_client.download_file(obj.bucket_name, obj.key, str(path / filename))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file('phrase-lookup', 'data/data_modified.csv', 'data_modified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_name, bucket_name, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = 'data/data_modified.csv'\n",
    "        \n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket_name, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../src/output_files\")\n",
    "file_name = str(data_path / 'data_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_file(file_name, 'phrase-lookup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
